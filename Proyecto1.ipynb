{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "    roc_auc_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Downloading stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"./data/cat_6716.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Treinta y una funcionan como empresas municipa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>El empoderamiento de los jóvenes, particularme...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>La descarga anual media a largo plazo del río ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Ninguna de estas leyes se redactó teniendo en ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Las inversiones en un sistema de \"usuarios fin...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Dada su importancia y con el fin de reflejar a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Los esfuerzos en curso para dar más espacio a ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>La importación parcial del sistema norteameric...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Los riesgos de producción agrícola también pue...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>Actualmente, varios tratados internacionales e...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Textos_espanol  sdg\n",
       "669   Treinta y una funcionan como empresas municipa...    6\n",
       "2849  El empoderamiento de los jóvenes, particularme...   16\n",
       "342   La descarga anual media a largo plazo del río ...    6\n",
       "872   Ninguna de estas leyes se redactó teniendo en ...    6\n",
       "596   Las inversiones en un sistema de \"usuarios fin...    6\n",
       "122   Dada su importancia y con el fin de reflejar a...    6\n",
       "62    Los esfuerzos en curso para dar más espacio a ...    6\n",
       "2268  La importación parcial del sistema norteameric...   16\n",
       "83    Los riesgos de producción agrícola también pue...    6\n",
       "2866  Actualmente, varios tratados internacionales e...   16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Textos_espanol    object\n",
       "sdg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Textos_espanol\"]= train_df[\"Textos_espanol\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(\"./data/SinEtiquetatest_cat_6716.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. 1. Introducción: Las Estructuras del Derech...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las aguas subterráneas se han debatido en el c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La presente contribución evalúa la jurispruden...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sin embargo, este crédito fiscal expira en 201...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este estudio explora las actitudes, comportami...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Este artículo explora la historia y el impacto...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Mientras que algunos dan mayor énfasis a la ma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Una innovación importante para garantizar el s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>El Salvador continúa luchando con niveles elev...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>También puede reflejar una baja conciencia sob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Textos_espanol  sdg\n",
       "0    1. 1. Introducción: Las Estructuras del Derech...  NaN\n",
       "1    Las aguas subterráneas se han debatido en el c...  NaN\n",
       "2    La presente contribución evalúa la jurispruden...  NaN\n",
       "3    Sin embargo, este crédito fiscal expira en 201...  NaN\n",
       "4    Este estudio explora las actitudes, comportami...  NaN\n",
       "..                                                 ...  ...\n",
       "975  Este artículo explora la historia y el impacto...  NaN\n",
       "976  Mientras que algunos dan mayor énfasis a la ma...  NaN\n",
       "977  Una innovación importante para garantizar el s...  NaN\n",
       "978  El Salvador continúa luchando con niveles elev...  NaN\n",
       "979  También puede reflejar una baja conciencia sob...  NaN\n",
       "\n",
       "[980 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pasa todo a minusculas y se eliminan signos de puntuacion y caracteres especiales para facilitar el procesamiento de las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se remueven \"Stop words\" o palabras genericas que no afectan el sentimieno general en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stop_words]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza la lematizacion para reducir palabras a su estado mas basico removiendo conjugaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "        \n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomado de https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Es importante destacar que, en un año de sequí...</td>\n",
       "      <td>6</td>\n",
       "      <td>importante destacar año sequía espera disminuy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hay una gran cantidad de literatura sobre Aust...</td>\n",
       "      <td>6</td>\n",
       "      <td>gran cantidad literatura australia área sugier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los procesos de descentralización, emprendidos...</td>\n",
       "      <td>6</td>\n",
       "      <td>procesos descentralización emprendidos serie a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Esto puede tener consecuencias sustanciales pa...</td>\n",
       "      <td>6</td>\n",
       "      <td>puede tener consecuencias sustanciales calidad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La función de beneficio también incorpora pará...</td>\n",
       "      <td>6</td>\n",
       "      <td>función beneficio incorpora parámetros afectan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Textos_espanol  sdg  \\\n",
       "0  Es importante destacar que, en un año de sequí...    6   \n",
       "1  Hay una gran cantidad de literatura sobre Aust...    6   \n",
       "2  Los procesos de descentralización, emprendidos...    6   \n",
       "3  Esto puede tener consecuencias sustanciales pa...    6   \n",
       "4  La función de beneficio también incorpora pará...    6   \n",
       "\n",
       "                                          clean_text  \n",
       "0  importante destacar año sequía espera disminuy...  \n",
       "1  gran cantidad literatura australia área sugier...  \n",
       "2  procesos descentralización emprendidos serie a...  \n",
       "3  puede tener consecuencias sustanciales calidad...  \n",
       "4  función beneficio incorpora parámetros afectan...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_text'] = train_df['Textos_espanol'].apply(lambda x: finalpreprocess(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que los modelos de clasificacion puedan trabajar con los datos es importante darles valores numericos primero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division de datos de entranamiento en entranamineto y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[\"clean_text\"],train_df[\"sdg\"],test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]\n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "train_df['clean_text_tok']=[nltk.word_tokenize(i) for i in train_df['clean_text']]\n",
    "model = Word2Vec(train_df['clean_text_tok'],min_count=1)   \n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors)) \n",
    "modelw = MeanEmbeddingVectorizer(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression (W2v)\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train)  #model\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_w2v.predict(X_val_vectors_w2v)\n",
    "y_prob = lr_w2v.predict_proba(X_val_vectors_w2v)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    "\n",
    "unique, counts = np.unique(y_predict, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\archivos 2023-2\\BI\\proyecto\\ProyectoBI\\Proyecto1.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fpr, tpr, thresholds \u001b[39m=\u001b[39m roc_curve(y_test, y_prob, pos_label \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m roc_auc \u001b[39m=\u001b[39m auc(fpr, tpr)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAUC:\u001b[39m\u001b[39m'\u001b[39m, roc_auc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label = 16)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 190, 7: 189, 16: 221}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\archivos 2023-2\\BI\\proyecto\\ProyectoBI\\Proyecto1.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fitting the model using Random Forest (W2v)  \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Rf \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Rf\u001b[39m.\u001b[39mfit(X_train_vectors_w2v, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/archivos%202023-2/BI/proyecto/ProyectoBI/Proyecto1.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#predict y value for test dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Fitting the model using Random Forest (W2v)  \n",
    "Rf = RandomForestClassifier(random_state=3)\n",
    "Rf.fit(X_train_vectors_w2v, y_train)\n",
    "#predict y value for test dataset\n",
    "predictions = Rf.predict(X_val_vectors_w2v)\n",
    "pred_prob = Rf.predict_proba(X_val_vectors_w2v)[:,1]\n",
    "print(classification_report(y_test,predictions))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que los resultados del algoritmo de random forest tiene un rendimiento similar al que obtuvimos al usar el de Logistic Regression, con algunas mejoras minimas en el F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = Rf.estimators_\n",
    "print(\"Number of trees:\", len(estimators))\n",
    "print(\"Trees depth (mean):\", np.mean([tree.get_depth() for tree in estimators]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
